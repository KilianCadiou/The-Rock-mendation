{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# modèle\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FONCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION 1\n",
    "\n",
    "def encodage_X(X, type, poids):\n",
    "  from sklearn.preprocessing import StandardScaler\n",
    "  index = X.index\n",
    "  X_num = X.select_dtypes('number')\n",
    "\n",
    "  if type == 'standard':\n",
    "      from sklearn.preprocessing import StandardScaler\n",
    "      SN = StandardScaler()\n",
    "      X_num_SN = pd.DataFrame(SN.fit_transform(X_num), columns=X_num.columns)\n",
    "\n",
    "  else:\n",
    "      from sklearn.preprocessing import MinMaxScaler\n",
    "      SN = MinMaxScaler()\n",
    "      X_num_SN = pd.DataFrame(SN.fit_transform(X_num), columns=X_num.columns)\n",
    "\n",
    "  X_num_SN = X_num_SN.mul(poids, axis = 1)\n",
    "  X_encoded = X_num_SN\n",
    "\n",
    "  X_encoded = X_encoded.dropna()\n",
    "\n",
    "  return X_encoded, SN\n",
    "\n",
    "# FONCTION 2\n",
    "\n",
    "def evaluate_k(X_encoded, k_range):\n",
    "    \"\"\"\n",
    "    Évalue différentes valeurs de k en utilisant la somme des distances aux voisins\n",
    "    et le score de silhouette comme métriques.\n",
    "\n",
    "    Args:\n",
    "        X_encoded (DataFrame): Données normalisées\n",
    "        k_range (range): Plage de valeurs de k à tester\n",
    "\n",
    "    Returns:\n",
    "        tuple: (distances moyennes, scores de silhouette)\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    avg_distances = []\n",
    "    silhouette_scores = []\n",
    "\n",
    "    for k in k_range:\n",
    "        # Calcul des distances moyennes pour chaque k\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        model = NearestNeighbors(n_neighbors=k)\n",
    "        model.fit(X_encoded)\n",
    "        distances, _ = model.kneighbors(X_encoded)\n",
    "        avg_distances.append(np.mean(distances))\n",
    "\n",
    "        # Calcul du score de silhouette\n",
    "        # Nous utilisons KMeans pour créer des clusters et évaluer la qualité\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        clusters = kmeans.fit_predict(X_encoded)\n",
    "        if k > 1:  # Le score de silhouette nécessite au moins 2 clusters\n",
    "            silhouette_scores.append(silhouette_score(X_encoded, clusters))\n",
    "        else:\n",
    "            silhouette_scores.append(0)\n",
    "\n",
    "    return avg_distances, silhouette_scores\n",
    "\n",
    "# FONCTION 3\n",
    "\n",
    "def encodage_predict(df_a_predire, SN, poids, X_encoded):\n",
    "  X_num = df_a_predire.select_dtypes('number')\n",
    "\n",
    "  X_num_SN = pd.DataFrame(SN.transform(X_num), columns=X_num.columns).reset_index(drop=True)\n",
    "  X_num_SN = X_num_SN.mul(poids, axis = 1)\n",
    "  \n",
    "  X_encoded_predire = X_num_SN\n",
    "\n",
    "  df_predict = X_encoded_predire\n",
    "\n",
    "  # DataFrame vide qui a les mêmes colonnes que X_encoded\n",
    "  df_final = pd.DataFrame(columns=X_encoded.columns)\n",
    "\n",
    "  # On veut que le DataFrame ait le même nombre de lignes que df_predict\n",
    "  df_final = df_final.reindex(index=df_predict.index)\n",
    "  # On met tous les NaN à False\n",
    "  df_final = df_final.fillna(False)\n",
    "\n",
    "  # On parcourt chaque colonne de df_predict\n",
    "  # Si la colonne est présente dans X_encoded alors on la garde\n",
    "  # Sinon, on la met à False\n",
    "  for column in df_predict.columns:\n",
    "    if column in X_encoded.columns:\n",
    "      df_final[column] = df_predict[column]\n",
    "\n",
    "  return df_final\n",
    "\n",
    "# FONCTION 4\n",
    "\n",
    "def pokemons_similaires(X, film_id, model, SN, poids, X_encoded, df):\n",
    "\n",
    "  # Vérifier si le Pokémon existe dans le dataset\n",
    "  if film_id not in X['film_id_out_KNN'].values:\n",
    "      return f\"Le Pokémon {film_id} n'est pas dans le dataset.\"\n",
    "\n",
    "  # Récupérer les caractéristiques du Pokémon\n",
    "  pokemon = X[X['film_id_out_KNN'] == film_id]\n",
    "\n",
    "  # Je recopie ce qu'on a fait avant:\n",
    "  caract_pokemon = X[X['film_id_out_KNN'] == film_id]\n",
    "\n",
    "  caract_pokemon_encoded = encodage_predict(caract_pokemon, SN, poids, X_encoded)\n",
    "\n",
    "  distances, indices = model.kneighbors(caract_pokemon_encoded)\n",
    "\n",
    "  return df.iloc[indices[0]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_list(element):\n",
    "    element = element.replace('\"', \"\").replace(\"[\", '').replace(\"]\", '').replace(\"'\", '')\n",
    "    element = element.split(', ')\n",
    "    return element\n",
    "\n",
    "def en_set(element):\n",
    "    element = set(element)\n",
    "    return element\n",
    "\n",
    "def list_propre(element):\n",
    "    element = str(element)\n",
    "    element = element.replace('\"', \"\").replace(\"[\", '').replace(\"]\", '').replace(\"'\", '')\n",
    "    return element\n",
    "\n",
    "def str_to_set(element):\n",
    "    element = element.replace('\"', \"\").replace(\"[\", '').replace(\"]\", '').replace(\"'\", '').replace(\", \", ',')\n",
    "    element = set(element.split(','))\n",
    "    return element\n",
    "\n",
    "def str_to_set_to_list(element):\n",
    "    element = element.replace('\"', \"\").replace(\"[\", '').replace(\"]\", '').replace(\"'\", '').replace(\", \", ',')\n",
    "    element = list(set(element.split(',')))\n",
    "    return element\n",
    "\n",
    "def debut2(titre):\n",
    "    titre = titre.lower().replace(\"'\", '').replace('(', '').replace(')', '').replace('[', '').replace(']', '').replace('{', '').replace('}', '').replace('/', '').replace(' ', '').replace('.', '').replace(',', '').replace('&', '').replace('?', '').replace('!', '')\n",
    "    titre_final = ''\n",
    "    if ':' in titre:\n",
    "        for n in range(len(titre)):\n",
    "            if titre[n] != ':':\n",
    "                if titre[n].isalpha() or titre[n].isnumeric():\n",
    "                    titre_final += titre[n]   \n",
    "            else:\n",
    "                break           \n",
    "\n",
    "    return titre_final\n",
    "\n",
    "def name(liste_films, df):\n",
    "\n",
    "    df = df.drop(['ordering', 'category', 'job', 'characters'], axis = 1)\n",
    "    df['nconst'] = df['nconst'] + ', '\n",
    "    df = df.groupby('tconst').sum()\n",
    "    df = df.reset_index()\n",
    "\n",
    "    df = pd.merge(liste_films,\n",
    "                  df,\n",
    "                  left_on = 'film_id_out_KNN',\n",
    "                  right_on = 'tconst',\n",
    "                  how = 'left')\n",
    "\n",
    "    df = df.drop('film_id_out_KNN', axis = 1)\n",
    "    df['nconst'] = df['nconst'].astype(str)\n",
    "    df['nconst'] = df['nconst'].apply(lambda x : x.split(','))\n",
    "    df = df.explode('nconst')\n",
    "    df['tconst'] = df['tconst'] + ','\n",
    "    df = df.groupby('nconst').sum()\n",
    "    df = df.reset_index()\n",
    "    df = df[~(df['nconst']== ' ')]\n",
    "    df['nconst'] = df['nconst'].astype(str)\n",
    "    df['tconst'] = df['tconst'].astype(str)\n",
    "    df['nconst'] = df['nconst'].apply(lambda x : x.replace(' ', ''))\n",
    "    df['tconst'] = df['tconst'].apply(lambda x : x.replace(' ', ''))\n",
    "\n",
    "    return df\n",
    "\n",
    "def acteur_name(df):\n",
    "\n",
    "    df['tconst_y'] = df['tconst_y'].astype(str)\n",
    "    df['tconst'] = df['tconst_x'] + df['tconst_y']\n",
    "    df = df[['nconst', 'primaryName', 'tconst']]\n",
    "    df['tconst'] = df['tconst'].apply(lambda x : x.replace(' ', '').replace('[', '').replace(']', '').replace(\"'\", ''))\n",
    "    df['tconst'] = df['tconst'].apply(lambda x : x.split(','))\n",
    "    df = df.rename({'tconst': 'knownForTitles'}, axis = 1)\n",
    "    df = df.rename({'nconst': 'acteur'}, axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def realisateur_name(df):\n",
    "    \n",
    "    df = df.groupby('nconst').sum()\n",
    "    df = df.reset_index()\n",
    "    df = pd.merge(df,\n",
    "                  df_title_crew,\n",
    "                  on = 'nconst',\n",
    "                  how = 'left')\n",
    "\n",
    "    df = df[~(df['nconst'] == 'nan')]\n",
    "    df['tconst_x'] = df['tconst_x'].astype(str)\n",
    "    df['tconst_y'] = df['tconst_y'].astype(str)\n",
    "    df['tconst'] = df['tconst_x'] + ',' + df['tconst_y']\n",
    "    df = df.drop(['tconst_y', 'tconst_x'], axis = 1)\n",
    "    df['tconst'] = df['tconst'].apply(lambda x : x.replace(' ', '').replace('[', '').replace(']', '').replace(\"'\", '').replace(\",,\", ','))\n",
    "    df['tconst'] = df['tconst'].astype(str)\n",
    "    df['tconst'] = df['tconst'].apply(lambda x : x.split(','))\n",
    "    df['tconst'] = df['tconst'].apply(lambda x : set(x))\n",
    "    df['tconst'] = df['tconst'].apply(lambda x : list(x))\n",
    "\n",
    "    df = pd.merge(df,\n",
    "                  df_name_basics,\n",
    "                  on = 'nconst',\n",
    "                  how = 'left')\n",
    "\n",
    "    df['tconst_x'] = df['tconst_x'].astype(str)\n",
    "    df['tconst_y'] = df['tconst_y'].astype(str)\n",
    "    df['tconst'] = df['tconst_x'] + ',' + df['tconst_y']\n",
    "    df = df.drop(['tconst_y', 'tconst_x'], axis = 1)\n",
    "    df['tconst'] = df['tconst'].apply(lambda x : x.replace(' ', '').replace('[', '').replace(']', '').replace(\"'\", '').replace(\",,\", ','))\n",
    "    df['tconst'] = df['tconst'].astype(str)\n",
    "    df['tconst'] = df['tconst'].apply(lambda x : x.split(','))\n",
    "    df['tconst'] = df['tconst'].apply(lambda x : set(x))\n",
    "    df['tconst'] = df['tconst'].apply(lambda x : list(x))\n",
    "\n",
    "    df = df.rename({'tconst': 'knownForTitles'}, axis = 1)\n",
    "    df = df.rename({'nconst': 'realisateurs'}, axis = 1)\n",
    "    df = df.explode('knownForTitles')\n",
    "    df = df[~(df['knownForTitles'] == '')]\n",
    "\n",
    "    return df\n",
    "\n",
    "def debut(titre):\n",
    "    titre = titre.lower().replace(' ', '')\n",
    "    titre_final = ''\n",
    "    for n in range(len(titre)):\n",
    "        if titre[n].isalpha():\n",
    "            titre_final += titre[n]\n",
    "    return titre_final[0:20]\n",
    "\n",
    "def len_pandas(x, colonne):\n",
    "    x_escaped = re.escape(x)\n",
    "    return df_films[df_films[f'{colonne}'].fillna('').str.contains(x_escaped, na=False, regex=True)].shape[0]\n",
    "\n",
    "def liste_recurrence(df_films, colonne):\n",
    "\n",
    "    df_films[colonne] = df_films[colonne].astype(str)\n",
    "    df_films[f'{colonne}2'] = df_films[colonne].apply(lambda x: x.replace('\"', \"\").replace(\"[\", '').replace(\"]\", '').replace(\"'\", '').replace(\" \", '').lower())\n",
    "    df_films[f'{colonne}'] = df_films[f'{colonne}2'].apply(lambda x : x.split(','))\n",
    "\n",
    "    liste= []\n",
    "\n",
    "    for genres in df_films[colonne] :\n",
    "        for element in genres:\n",
    "            liste.append(element)\n",
    "\n",
    "    set_liste = set(liste)\n",
    "\n",
    "    if 'nan' in set_liste:\n",
    "        set_liste.remove('nan')\n",
    "    if \"\" in set_liste:\n",
    "        set_liste.remove(\"\")\n",
    "\n",
    "    dico_production_companies_name_out_KNN = {}\n",
    "\n",
    "    for element in set_liste:\n",
    "        if colonne == 'production_companies_name_out_KNN':\n",
    "            if liste.count(element) > apparition_production:\n",
    "                if len(element) > len_production:\n",
    "                    dico_production_companies_name_out_KNN.update({element : liste.count(element)})\n",
    "        else:\n",
    "            dico_production_companies_name_out_KNN.update({element : liste.count(element)})\n",
    "\n",
    "    sorted_set = dict(sorted(dico_production_companies_name_out_KNN.items(), key=lambda item:item[1], reverse = True))\n",
    "    \n",
    "    limite_realisateurs = 100\n",
    "    limite_acteur = 200\n",
    "    limite_production_companies_name = 100\n",
    "    limite_genre = len(set_liste)\n",
    "\n",
    "    if colonne == 'acteur_out_KNN':\n",
    "        limite = limite_acteur\n",
    "    elif colonne == 'realisateurs_out_KNN':\n",
    "        limite = limite_realisateurs\n",
    "    elif colonne == 'production_companies_name_out_KNN':\n",
    "        limite = limite_production_companies_name\n",
    "    elif colonne == 'genre_out_KNN':\n",
    "        limite = limite_genre\n",
    "\n",
    "    liste_totale = list(sorted_set.keys())\n",
    "\n",
    "    if len(liste_totale) > limite_liste:\n",
    "        liste_totale = liste_totale[:limite_liste]\n",
    "\n",
    "    \n",
    "    liste_limitee = liste_totale[:limite]\n",
    "\n",
    "    return liste_totale, liste_limitee\n",
    "\n",
    "def classement_element(df_films, colonne, liste_totale, dico_total_final):\n",
    "\n",
    "  if colonne in ['acteur_out_KNN', 'realisateurs_out_KNN']:\n",
    "    df_films[f'trie_{colonne}'] = ''\n",
    "    df_films[f'name_trie_{colonne}'] = ''\n",
    "\n",
    "    for element in liste_totale:\n",
    "      df_films[f'trie_{colonne}'] = df_films.apply(lambda row : (row[f'trie_{colonne}'] + f', {element}') if element in row[colonne] else row[f'trie_{colonne}'], axis = 1)\n",
    "      df_films[f'name_trie_{colonne}'] = df_films.apply(lambda row : (row[f'name_trie_{colonne}'] + f', {dico_total_final[element]}') if element in row[colonne] else row[f'name_trie_{colonne}'], axis = 1)\n",
    "    \n",
    "    df_films[f'trie_{colonne}'] = df_films[f'trie_{colonne}'].apply(lambda x : x[2:])\n",
    "    df_films[f'name_trie_{colonne}'] = df_films[f'name_trie_{colonne}'].apply(lambda x : x[2:])\n",
    "\n",
    "    df_films[f'trie_{colonne}'] = df_films[f'trie_{colonne}'].apply(lambda x : x.split(', '))\n",
    "    df_films[f'name_trie_{colonne}'] = df_films[f'name_trie_{colonne}'].apply(lambda x : x.split(', '))\n",
    "\n",
    "  else:\n",
    "    df_films[f'trie_{colonne}'] = ''\n",
    "\n",
    "    for element in liste_totale:\n",
    "      df_films[f'trie_{colonne}'] = df_films.apply(lambda row : (row[f'trie_{colonne}'] + f', {element}') if element in row[colonne] else row[f'trie_{colonne}'], axis = 1)\n",
    "\n",
    "    df_films[f'trie_{colonne}'] = df_films[f'trie_{colonne}'].apply(lambda x : x[2:])\n",
    "\n",
    "    df_films[f'trie_{colonne}'] = df_films[f'trie_{colonne}'].apply(lambda x : x.split(', '))\n",
    "\n",
    "def bool_colonnes(df_films, liste, colonne):\n",
    "\n",
    "    for genre in liste:\n",
    "        df_films[f'{colonne[:-8]}_{genre}'] = df_films[f'{colonne}'].apply(lambda x: genre in x)\n",
    "\n",
    "def transfo_col_bool(df_films):\n",
    "\n",
    "    df_films_not_bool = df_films.select_dtypes(exclude = 'bool')\n",
    "    df_films_bool = df_films.select_dtypes(include = 'bool')\n",
    "    df_films_bool = df_films_bool.astype(str)\n",
    "    df_films_bool = df_films_bool.replace('True', '1').replace('False', '0')\n",
    "    df_films_bool = df_films_bool.astype(int)\n",
    "    df_films = pd.concat([df_films_not_bool, df_films_bool], axis = 1)\n",
    "    df_films_not_bool, df_films_bool = 0, 0\n",
    "\n",
    "    return df_films\n",
    "\n",
    "def colonne_debut_titre(df_films, colonne):\n",
    "\n",
    "    liste_titres = []\n",
    "\n",
    "    for n in range(len(df_films)):\n",
    "        liste_titres.append(debut2(df_films[colonne].iloc[n]))\n",
    "\n",
    "    dico_titres = {}\n",
    "    set_titres = set(liste_titres)\n",
    "\n",
    "    for element in set_titres:\n",
    "        if len(element) > 4:\n",
    "            if liste_titres.count(element) >=3:\n",
    "                dico_titres.update({element : liste_titres.count(element)})\n",
    "\n",
    "    if '' in set_titres:\n",
    "        set_titres.remove('')\n",
    "        \n",
    "    sorted_dico_titres = dict(sorted(dico_titres.items(), key=lambda item:item[1], reverse = True))  \n",
    "\n",
    "    df_films[f'debut{colonne}'] = df_films[colonne].apply(debut2)\n",
    "\n",
    "    df_films[f'debut_critere_{colonne}'] = ''\n",
    "\n",
    "    df_films[f'debut_critere_{colonne}'] = df_films.apply(lambda x : x[f'debut{colonne}'] if x[f'debut{colonne}'] in sorted_dico_titres.keys() else '', axis = 1)\n",
    "    df_films[f'debut_critere_{colonne}'] = df_films[f'debut_critere_{colonne}'].apply(lambda x : x.split())\n",
    "\n",
    "    liste_limitee_title = sorted_dico_titres.keys()\n",
    "\n",
    "    return liste_limitee_title\n",
    "\n",
    "\n",
    "def clean_list(element):\n",
    "\n",
    "    for element2 in element:\n",
    "        if element2 == '':\n",
    "            element.remove(element2)\n",
    "        if element2 == 'nan':\n",
    "            element.remove(element2)\n",
    "\n",
    "    return element\n",
    "            \n",
    "def list_colonnes(df_films, colonne):\n",
    "\n",
    "    df_films[colonne] = df_films[colonne].astype(str)\n",
    "    df_films[f'{colonne}2'] = df_films[colonne].apply(lambda x: x.replace('\"', \"\").replace(\"[\", '').replace(\"]\", '').replace(\"'\", '').replace(\" \", '').lower())\n",
    "    df_films[f'{colonne}2'] = df_films[f'{colonne}2'].apply(lambda x : x.replace('nan', '') if 'nan' in x else x)\n",
    "    df_films[f'{colonne}'] = df_films[f'{colonne}2'].apply(lambda x : x.split(','))\n",
    "    df_films[f'{colonne}'] = df_films[f'{colonne}'].apply(lambda x : clean_list(x))\n",
    "\n",
    "def titre(id):\n",
    "  navigator = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1)'\n",
    "  url_base = 'https://www.imdb.com/fr/title/'\n",
    "  url_finale = f'{url_base}{id}'  \n",
    "\n",
    "  html = requests.get(url_finale, headers={'User-Agent': navigator})\n",
    "  html2 = html.content\n",
    "  soup = BeautifulSoup(html2, 'html.parser')\n",
    "\n",
    "  liste_titre = []\n",
    "  for balise_parent in soup.find_all('span', class_='hero__primary-text'):\n",
    "      try:\n",
    "        liste_titre.append(balise_parent.get_text().strip())\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "  if len(liste_titre) > 0:\n",
    "    titre = liste_titre[0]\n",
    "  else:\n",
    "    titre = 'Unknown'\n",
    "  \n",
    "  return titre\n",
    "\n",
    "def note(id):\n",
    "  navigator = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1)'\n",
    "  url_base = 'https://www.imdb.com/fr/title/'\n",
    "  url_finale = f'{url_base}{id}'  \n",
    "\n",
    "  html = requests.get(url_finale, headers={'User-Agent': navigator})\n",
    "  html2 = html.content\n",
    "  soup = BeautifulSoup(html2, 'html.parser')\n",
    "\n",
    "  liste_note = []\n",
    "  for balise_parent in soup.find_all('span', class_='sc-d541859f-1 imUuxf'):\n",
    "      try:\n",
    "        liste_note.append(balise_parent.get_text().strip())\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "  if len(liste_note) > 0:\n",
    "    note = liste_note[0]\n",
    "  else:\n",
    "    note = 'Unknown'\n",
    "  \n",
    "  return note\n",
    "\n",
    "def popularity(id):\n",
    "  navigator = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1)'\n",
    "  url_base = 'https://www.imdb.com/fr/title/'\n",
    "  url_finale = f'{url_base}{id}'  \n",
    "\n",
    "  html = requests.get(url_finale, headers={'User-Agent': navigator})\n",
    "  html2 = html.content\n",
    "  soup = BeautifulSoup(html2, 'html.parser')\n",
    "\n",
    "  liste_popularity = []\n",
    "  for balise_parent in soup.find_all('div', class_='sc-39d285cf-1 dxqvqi'):\n",
    "      try:\n",
    "        liste_popularity.append(balise_parent.get_text().strip())\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "  if len(liste_popularity) > 0:\n",
    "    popularity = liste_popularity[0]\n",
    "  else:\n",
    "    popularity = 'Unknown'\n",
    "  \n",
    "  return popularity\n",
    "\n",
    "def realisateur(id):\n",
    "  navigator = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1)'\n",
    "  url_base = 'https://www.imdb.com/fr/title/'\n",
    "  url_finale = f'{url_base}{id}'  \n",
    "\n",
    "  html = requests.get(url_finale, headers={'User-Agent': navigator})\n",
    "  html2 = html.content\n",
    "  soup = BeautifulSoup(html2, 'html.parser')\n",
    "\n",
    "  liste_realisateur = []\n",
    "  for balise_parent in soup.find_all('a', class_='ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'):\n",
    "      try:\n",
    "        liste_realisateur.append(balise_parent.get_text().strip())\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "  if len(liste_realisateur) > 0:\n",
    "    realisateur = liste_realisateur[0]\n",
    "  else:\n",
    "    realisateur = 'Unknown'\n",
    "  \n",
    "  return realisateur\n",
    "\n",
    "def acteurs(id):\n",
    "  navigator = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1)'\n",
    "  url_base = 'https://www.imdb.com/fr/title/'\n",
    "  url_finale = f'{url_base}{id}'  \n",
    "\n",
    "  html = requests.get(url_finale, headers={'User-Agent': navigator})\n",
    "  html2 = html.content\n",
    "  soup = BeautifulSoup(html2, 'html.parser')\n",
    "\n",
    "  liste_acteurs = []\n",
    "  for balise_parent in soup.find_all('a', class_='sc-cd7dc4b7-1 kVdWAO'):\n",
    "        try:\n",
    "          liste_acteurs.append(balise_parent.get_text().strip())\n",
    "        except:\n",
    "          pass\n",
    "\n",
    "  if len(liste_acteurs) > 5:\n",
    "    acteurs = liste_acteurs[:5]\n",
    "  else:\n",
    "    acteurs = 'Unknown'\n",
    "  \n",
    "  return acteurs\n",
    "\n",
    "\n",
    "def annee(id):\n",
    "  navigator = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1)'\n",
    "  url_base = 'https://www.imdb.com/fr/title/'\n",
    "  url_finale = f'{url_base}{id}'  \n",
    "\n",
    "  html = requests.get(url_finale, headers={'User-Agent': navigator})\n",
    "  html2 = html.content\n",
    "  soup = BeautifulSoup(html2, 'html.parser')\n",
    "\n",
    "  liste_annee = []\n",
    "  for balise_parent in soup.find_all('a', class_='ipc-link ipc-link--baseAlt ipc-link--inherit-color'):\n",
    "        try:\n",
    "          if balise_parent.get_text().strip()[0] == '1' or balise_parent.get_text().strip()[0] == '2':\n",
    "            liste_annee.append(balise_parent.get_text().strip())\n",
    "        except:\n",
    "          pass\n",
    "\n",
    "  if len(liste_annee) > 0:\n",
    "    annee = liste_annee[0]\n",
    "  else:\n",
    "    annee = 'Unknown'\n",
    "  \n",
    "  return annee\n",
    "\n",
    "def affiche(id): \n",
    "  \n",
    "  navigator = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1)'\n",
    "  url_base = 'https://www.imdb.com/fr/title/'\n",
    "  url_finale = f'{url_base}{id}' \n",
    "\n",
    "  html = requests.get(url_finale, headers={'User-Agent': navigator})\n",
    "  html2 = html.content\n",
    "  soup = BeautifulSoup(html2, 'html.parser')\n",
    "  affiche = ''\n",
    "\n",
    "  for balise_parent in soup.find_all('div', class_='ipc-page-content-container ipc-page-content-container--center'):\n",
    "    for element in balise_parent.find_all('img', class_='ipc-image'):\n",
    "      affiche += f\", {element['src']}\"\n",
    "\n",
    "  affiche = affiche.split(', ')\n",
    "\n",
    "  if \"\" in affiche:\n",
    "    affiche.remove(\"\")\n",
    "\n",
    "  lien = affiche[0]\n",
    "\n",
    "  return lien\n",
    "\n",
    "def resume(id):\n",
    "\n",
    "  navigator = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1)'\n",
    "  url_base = 'https://www.imdb.com/fr/title/'\n",
    "  url_finale = f'{url_base}{id}'\n",
    "\n",
    "  html = requests.get(url_finale, headers={'User-Agent': navigator})\n",
    "  html2 = html.content\n",
    "  soup = BeautifulSoup(html2, 'html.parser')\n",
    "\n",
    "  html = requests.get(url_finale, headers={'User-Agent': navigator})\n",
    "  html2 = html.content\n",
    "  soup = BeautifulSoup(html2, 'html.parser')\n",
    "\n",
    "  for balise_parent in soup.find_all('span', class_='sc-3ac15c8d-1 gkeSEi'):\n",
    "    resume = balise_parent.get_text().strip()\n",
    "\n",
    "  return resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS ET MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmbd_full = pd.read_csv('/Users/kilian/Documents/GitHub/The-Rock-mendation/BD/tmdb_full.csv', na_values= ['\\\\N'])\n",
    "for element in df_tmbd_full.columns:\n",
    "    df_tmbd_full = df_tmbd_full.rename({element : f'{element}_tmdb'}, axis = 1)\n",
    "    \n",
    "df_tmbd_full = df_tmbd_full.drop(['budget_tmdb','revenue_tmdb'], axis = 1)\n",
    "\n",
    "df_tmbd_full = df_tmbd_full.rename({'imdb_id_tmdb': 'film_id_tmbd',\n",
    "                                    'original_language_tmdb': 'language1_tmdb',\n",
    "                                    'original_title_tmdb' : 'title1_tmdb',\n",
    "                                    'release_date_tmdb': 'year1_tmdb',\n",
    "                                    'spoken_languages_tmdb' : 'language2_tmdb',\n",
    "                                    'vote_average_tmdb' : 'vote_exact_tmdb',\n",
    "                                    'production_companies_country_tmdb': 'country2_tmdb',\n",
    "                                    'title_tmdb' : 'title2_tmdb'}, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRI ET NETTOYAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = df_tmbd_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DROP DES DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = df_films.drop_duplicates(subset = 'film_id_tmbd', keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POPULARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = df_films.rename({'popularity_tmdb' : 'popularity_final',\n",
    "                            'runtime_tmdb' : 'runtime_final',\n",
    "                            'year1_tmdb' : 'year_final',\n",
    "                            'vote_exact_tmdb' : 'vote_exact_final',\n",
    "                            'vote_count_final' : 'vote_count_final',\n",
    "                            'production_companies_name_tmdb': 'production_companies_name_final',\n",
    "                            'genres_tmdb' : 'genre_final',\n",
    "                            'vote_count_tmdb' : 'vote_count_final'}, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUNTIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YEAR + DECENNIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['year_final'] = pd.to_datetime(df_films['year_final']).dt.year\n",
    "\n",
    "df_films['year_final'] = df_films['year_final'].fillna(0)\n",
    "df_films['year_final'] = df_films['year_final'].apply(lambda x : float(x))\n",
    "df_films['year_final'] = df_films['year_final'].apply(lambda x : int(x))\n",
    "\n",
    "df_films['Decennie'] = ''\n",
    "df_films['year_final'] = df_films['year_final'].astype(str)\n",
    "df_films['Decennie'] = df_films['year_final'] .str[:3] + \"0\"\n",
    "df_films['year_final']  = pd.to_numeric(df_films['year_final'] )\n",
    "df_films['Decennie'] = pd.to_numeric(df_films['Decennie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOTE EXACT + VOTE ARRONDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['vote_exact_final'] = df_films['vote_exact_final'].fillna(0)\n",
    "df_films['vote_exact_final'] = df_films['vote_exact_final'].astype(float)\n",
    "df_films['vote_arrondi_final'] = df_films['vote_exact_final'].apply(lambda x : int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['genre_final'] = df_films['genre_final'].apply(lambda x : str_to_set_to_list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LANGUAGE + COUNTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travail = ['language', 'country']\n",
    "colonnes = []\n",
    "for element in df_films.columns:\n",
    "    for element2 in travail:\n",
    "        if element2 in element:\n",
    "            colonnes.append(element)\n",
    "\n",
    "df_country = df_films[colonnes]\n",
    "\n",
    "for element in df_country.columns:\n",
    "    df_country[element] = df_country[element].astype(str)\n",
    "    df_country[element] = df_country[element].apply(lambda x : list_propre(x.lower()))\n",
    "    df_country[element] = df_country[element].apply(lambda x : np.nan if x == 'nan' else x)\n",
    "\n",
    "df_country['language_total'] = df_country['language1_tmdb'] + ',' + df_country['language2_tmdb'] + ',' + df_country['country2_tmdb']\n",
    "\n",
    "df_country['language_total'] = df_country['language_total'].astype(str)\n",
    "df_films['language_total_FR_ou_US'] = ''\n",
    "df_films['language_total_FR_ou_US'] = df_country.apply(lambda x : 'True' if 'fr' in x['language_total'] or 'en' in x['language_total'] or 'us' in x['language_total'] or x['language_total'] == 'nan' else 'False', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRODUCTION COUNTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['production_countries_tmdb'] = df_films['production_countries_tmdb'].apply(lambda x : str_to_set_to_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['prod_FR'] = df_films.apply(lambda row : 1 if 'FR' in row['production_countries_tmdb'] else 0, axis = 1)\n",
    "df_films['prod_US'] = df_films.apply(lambda row : 1 if 'US' in row['production_countries_tmdb'] else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRODUCTION COMPANY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['production_companies_name_final'] = df_films['production_companies_name_final'].apply(lambda x : str_to_set_to_list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['title_out_KNN'] = df_films.apply(lambda x : x['title2_tmdb'] + ', ' + x['title1_tmdb'] if x['title2_tmdb'] != x['title1_tmdb'] else x['title2_tmdb'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ON GARDE SEULEMENT LES COLONNES SOUHAITEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = df_films[['title_out_KNN', 'adult_tmdb', 'backdrop_path_tmdb', 'homepage_tmdb',\n",
    "                     'film_id_tmbd', 'overview_tmdb', 'popularity_final', 'poster_path_tmdb',\n",
    "                     'status_tmdb', 'tagline_tmdb', 'video_tmdb', 'production_companies_name_final', 'runtime_final',\n",
    "                     'Decennie', 'year_final', 'vote_exact_final', 'vote_arrondi_final', 'genre_final', 'production_countries_tmdb', 'language_total_FR_ou_US',\n",
    "                     'prod_US', 'prod_FR', 'vote_count_final']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = df_films.rename({'adult_tmdb' : 'adult_out_KNN',\n",
    "                            'backdrop_path_tmdb' : 'backdrop_path_out_KNN',\n",
    "                            'homepage_tmdb' : 'homepage_out_KNN',\n",
    "                            'film_id_tmbd' : 'film_id_out_KNN',\n",
    "                            'overview_tmdb' : 'overview_out_KNN',\n",
    "                            'poster_path_tmdb' : 'poster_path_out_KNN',\n",
    "                            'status_tmdb' : 'status_out_KNN',\n",
    "                            'tagline_tmdb' : 'tagline_tmdb_out_KNN',\n",
    "                            'video_tmdb' : 'video_tmdb_out_KNN',\n",
    "                            'production_countries_tmdb' : 'production_countries_out_KNN',\n",
    "                            'language_total_FR_ou_US' : 'language_total_FR_ou_US_out_KNN',\n",
    "                            'genre_final' : 'genre_out_KNN',\n",
    "                            'production_companies_name_final':'production_companies_name_out_KNN',\n",
    "                            'status_tmdb' : 'status_out_KNN'}, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DROP DES DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = df_films.drop_duplicates(subset = 'film_id_out_KNN', keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHOIX DES CRITERES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUR DF\n",
    "\n",
    "df_films = df_films[df_films['Decennie'] >= 1990]\n",
    "df_films = df_films[df_films['vote_exact_final'] > 3]\n",
    "df_films = df_films[df_films['runtime_final'] > 60]\n",
    "df_films = df_films[df_films['status_out_KNN'] == 'Released']\n",
    "df_films = df_films[df_films['language_total_FR_ou_US_out_KNN'] == 'True']\n",
    "\n",
    "\n",
    "# POUR FONCTIONS\n",
    "limite_liste = 500\n",
    "apparition_realisateur = 8\n",
    "apparition_acteur = 10\n",
    "apparition_production = 5\n",
    "len_production = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['vote_exact_final'] = df_films['vote_exact_final'].apply(lambda x : 0 if x == 'Unknown' else x)\n",
    "df_films['vote_exact_final'] = df_films['vote_exact_final'].astype(float)\n",
    "df_films['vote_arrondi_final'] = df_films['vote_exact_final'].apply(lambda x : int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['Decennie'] = ''\n",
    "df_films['year_final'] = df_films['year_final'].astype(str)\n",
    "df_films['Decennie'] = df_films['year_final'] .str[:3] + \"0\"\n",
    "df_films['year_final']  = pd.to_numeric(df_films['year_final'] )\n",
    "df_films['Decennie'] = pd.to_numeric(df_films['Decennie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACTEURS ET REALISATEURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_films = pd.DataFrame(df_films['film_id_out_KNN'])\n",
    "liste_films = liste_films.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_principals = pd.read_csv('/Users/kilian/Documents/GitHub/The-Rock-mendation/BD/title.principals.tsv.gz', compression = 'gzip', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acteurs = df_title_principals[(df_title_principals['category'] == 'actor') | (df_title_principals['category'] == 'actress') | (df_title_principals['category'] == 'self')]\n",
    "\n",
    "df_realisateurs = df_title_principals[df_title_principals['category'] == 'director']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_principals = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_crew = pd.read_csv('/Users/kilian/Documents/GitHub/The-Rock-mendation/BD/title.crew.tsv.gz', compression = 'gzip', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_crew = df_title_crew.drop('writers', axis = 1)\n",
    "\n",
    "df_title_crew = pd.merge(liste_films,\n",
    "                         df_title_crew,\n",
    "                         left_on = 'film_id_out_KNN',\n",
    "                         right_on = 'tconst',\n",
    "                         how = 'left')\n",
    "\n",
    "df_title_crew = df_title_crew.drop('film_id_out_KNN', axis = 1)\n",
    "\n",
    "df_title_crew = df_title_crew.rename({'directors': 'nconst'}, axis = 1)\n",
    "\n",
    "df_title_crew['nconst'] = df_title_crew['nconst'].astype(str)\n",
    "\n",
    "df_title_crew['nconst'] = df_title_crew['nconst'].apply(lambda x : x.split(\",\"))\n",
    "\n",
    "df_title_crew = df_title_crew.explode('nconst')\n",
    "\n",
    "df_title_crew = df_title_crew[~(df_title_crew['nconst'] == \" \")]\n",
    "\n",
    "df_title_crew['tconst'] = df_title_crew['tconst'] + ', '\n",
    "\n",
    "df_title_crew = df_title_crew.groupby('nconst').sum()\n",
    "\n",
    "df_title_crew = df_title_crew.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name_basics = pd.read_csv('/Users/kilian/Documents/GitHub/The-Rock-mendation/BD/name.basics.tsv.gz', compression = 'gzip', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name_basics = df_name_basics.drop(['birthYear', 'deathYear', 'primaryProfession'], axis = 1)\n",
    "\n",
    "df_name_basics = df_name_basics.rename({'knownForTitles' : 'tconst'}, axis = 1)\n",
    "\n",
    "df_name_basics['tconst'] = df_name_basics['tconst'].apply(lambda x : x.split(','))\n",
    "\n",
    "df_name_basics['nconst'] = df_name_basics['nconst'].astype(str)\n",
    "\n",
    "df_name_basics['nconst'] = df_name_basics['nconst'].apply(lambda x : x.replace(' ', ''))\n",
    "\n",
    "df_acteurs = name(liste_films, df_acteurs)\n",
    "\n",
    "df_realisateurs = name(liste_films, df_realisateurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acteurs_name = pd.merge(df_acteurs,\n",
    "                            df_name_basics,\n",
    "                            on = 'nconst',\n",
    "                            how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acteurs = 0\n",
    "df_acteurs_name = acteur_name(df_acteurs_name)\n",
    "df_realisateurs_name = realisateur_name(df_realisateurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acteurs, df_realisateurs, df_name_basics, df_title_crew = 0, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realisateurs_name.to_csv('P2_G5_realisateurs.csv.gz', index=False, compression='gzip')\n",
    "df_realisateurs = df_realisateurs_name\n",
    "\n",
    "df_acteurs_name.to_csv('P2_G5_acteurs.csv.gz', index=False, compression='gzip')\n",
    "df_acteurs = df_acteurs_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF ACTEURS\n",
    " \n",
    "df_acteurs = df_acteurs.rename({'knownForTitles' : 'films'}, axis = 1)\n",
    "\n",
    "df_acteurs2 = df_acteurs.explode('films')\n",
    "\n",
    "acteurs_repetitions = pd.DataFrame(df_acteurs2['acteur'].value_counts()).reset_index()\n",
    "\n",
    "acteurs_repetitions = acteurs_repetitions[acteurs_repetitions['count'] > apparition_acteur]\n",
    "\n",
    "acteurs_recurrents = pd.merge(acteurs_repetitions,\n",
    "                              df_acteurs,\n",
    "                              how = 'left',\n",
    "                              on = 'acteur')\n",
    "\n",
    "acteurs_recurrents2 = acteurs_recurrents.explode('films')\n",
    "\n",
    "acteurs_recurrents2['films'] = acteurs_recurrents2['films'].str.replace(\"'\",\"\")\n",
    "acteurs_recurrents2['acteur'] = acteurs_recurrents2['acteur'] + ', '\n",
    "\n",
    "acteurs_recurrents2 = acteurs_recurrents2.groupby('films').sum()\n",
    "\n",
    "acteurs_recurrents2['acteur'] = acteurs_recurrents2['acteur'].astype(str)\n",
    "\n",
    "acteurs_recurrents2['acteur'] = acteurs_recurrents2['acteur'].apply(lambda x : x.replace(\", , \", ''))\n",
    "\n",
    "acteurs_recurrents2 = acteurs_recurrents2.reset_index()\n",
    "acteurs_recurrents2 = acteurs_recurrents2[['films', 'acteur']]\n",
    "\n",
    "df_films = pd.merge(df_films,\n",
    "                    acteurs_recurrents2,\n",
    "                    how = 'left',\n",
    "                    left_on = 'film_id_out_KNN',\n",
    "                    right_on = 'films')\n",
    "\n",
    "acteurs_repetitions['acteur'] = acteurs_repetitions['acteur'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF REALISATEURS\n",
    "\n",
    "realisateurs_repetitions = pd.DataFrame(df_realisateurs['realisateurs'].value_counts()).reset_index()\n",
    "\n",
    "realisateurs_repetitions = realisateurs_repetitions[realisateurs_repetitions['count'] > apparition_realisateur]\n",
    "\n",
    "realisateurs_repetitions2 = realisateurs_repetitions.groupby('realisateurs').sum()\n",
    "\n",
    "realisateurs_repetitions2 = realisateurs_repetitions2.reset_index()\n",
    "\n",
    "realisateurs_connus = pd.merge(realisateurs_repetitions2,\n",
    "                               df_realisateurs,\n",
    "                               on = 'realisateurs',\n",
    "                               how = 'left')\n",
    "\n",
    "realisateurs_connus = realisateurs_connus[['knownForTitles', 'realisateurs']]\n",
    "\n",
    "realisateurs_connus['realisateurs'] = realisateurs_connus['realisateurs'] + ','\n",
    "\n",
    "realisateurs_connus2 = realisateurs_connus.groupby('knownForTitles').sum()\n",
    "\n",
    "df_films = pd.merge(df_films,\n",
    "                    realisateurs_connus2,\n",
    "                    how = 'left',\n",
    "                    left_on = 'film_id_out_KNN',\n",
    "                    right_on = 'knownForTitles')\n",
    "\n",
    "df_realisateurs['realisateurs'] = df_realisateurs['realisateurs'].astype(str)\n",
    "\n",
    "df_films['realisateurs'] = df_films['realisateurs'].astype(str)\n",
    "\n",
    "df_films = df_films.rename({'acteur' : 'acteur_out_KNN',\n",
    "                            'realisateurs' : 'realisateurs_out_KNN'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realisateurs_name = pd.read_csv('/Users/kilian/Documents/GitHub/The-Rock-mendation/Codes/P2_G5_realisateurs.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acteurs_name = pd.read_csv('/Users/kilian/Documents/GitHub/The-Rock-mendation/Codes/P2_G5_acteurs.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realisateurs_name['knownForTitles'] = df_realisateurs_name['knownForTitles'] + ','\n",
    "df_realisateurs_name['primaryName'] = df_realisateurs_name['primaryName'] + ','\n",
    "\n",
    "df_realisateurs_name = df_realisateurs_name.groupby('realisateurs').sum()\n",
    "\n",
    "df_realisateurs_name['primaryName'] = df_realisateurs_name['primaryName'].apply(lambda x : x.split(','))\n",
    "df_realisateurs_name['primaryName'] = df_realisateurs_name['primaryName'].apply(lambda x : set(x))\n",
    "df_realisateurs_name['primaryName'] = df_realisateurs_name['primaryName'].apply(lambda x : str(x))\n",
    "df_realisateurs_name['primaryName'] = df_realisateurs_name['primaryName'].apply(lambda x : x.replace('{', '').replace('}', '').replace(',', '').replace('\"', \"\").replace(\"[\", '').replace(\"]\", '').replace(\"'\", ''))\n",
    "\n",
    "df_realisateurs_name['knownForTitles'] = df_realisateurs_name['knownForTitles'].apply(lambda x : x.split(','))\n",
    "df_realisateurs_name['knownForTitles'] = df_realisateurs_name['knownForTitles'].apply(lambda x : set(x))\n",
    "df_realisateurs_name = df_realisateurs_name.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_acteurs = {}\n",
    "\n",
    "for n in range(len(df_acteurs_name)):\n",
    "    dico_acteurs.update({df_acteurs_name['acteur'].iloc[n] : df_acteurs_name['primaryName'].iloc[n]})\n",
    "\n",
    "dico_realisateurs = {}\n",
    "\n",
    "for n in range(len(df_realisateurs_name)):\n",
    "    dico_realisateurs.update({df_realisateurs_name['realisateurs'].iloc[n] : df_realisateurs_name['primaryName'].iloc[n][1:]})\n",
    "\n",
    "dico_total = dico_acteurs | dico_realisateurs\n",
    "\n",
    "dico_total_final = {}\n",
    "\n",
    "for element in dico_total:\n",
    "    if element not in dico_total_final.keys():\n",
    "        dico_total_final.update({element : dico_total[element]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_colonnes(df_films,'realisateurs_out_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_totale_realisateurs, liste_limitee_realisateurs = liste_recurrence(df_films, 'realisateurs_out_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classement_element(df_films, 'realisateurs_out_KNN', liste_totale_realisateurs, dico_total_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_colonnes(df_films, liste_limitee_realisateurs, 'realisateurs_out_KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACTEURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_colonnes(df_films,'acteur_out_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_totale_acteur, liste_limitee_acteur = liste_recurrence(df_films, 'acteur_out_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classement_element(df_films, 'acteur_out_KNN', liste_totale_acteur, dico_total_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_colonnes(df_films, liste_limitee_acteur, 'acteur_out_KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_colonnes(df_films,'genre_out_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_totale_genre, liste_limitee_genre = liste_recurrence(df_films, 'genre_out_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classement_element(df_films, 'genre_out_KNN', liste_totale_genre, dico_total_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_colonnes(df_films, liste_limitee_genre, 'genre_out_KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRODUCTION COMPANY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_colonnes(df_films,'production_companies_name_out_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_totale_production, liste_limitee_production = liste_recurrence(df_films, 'production_companies_name_out_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classement_element(df_films, 'production_companies_name_out_KNN', liste_totale_production, dico_total_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_colonnes(df_films, liste_limitee_production, 'production_companies_name_out_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['production_companies_name_Marvel'] = df_films['production_companies_name_out_KNN'].apply(lambda x: 'marvel' in x)\n",
    "df_films['production_companies_name_Disney'] = df_films['production_companies_name_out_KNN'].apply(lambda x: 'disney' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEBUT DE TITRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def title(id):\n",
    "\n",
    "#     url = f\"https://api.themoviedb.org/3/find/{id}?external_source=imdb_id&language=fr-FR\"\n",
    "\n",
    "#     headers = {\n",
    "#         \"accept\": \"application/json\",\n",
    "#         \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIzY2Y0YmE2ZDViMjQ2OWE1MGJhY2MyMTg1NDVjNTljOCIsIm5iZiI6MTc0MDYwNjIwOS45Njg5OTk5LCJzdWIiOiI2N2JmOGIwMWMwMjkxMzliMGUzNTg4N2UiLCJzY29wZXMiOlsiYXBpX3JlYWQiXSwidmVyc2lvbiI6MX0.BpGHsPbhRc9NXkVWVw9xtWQXsbdipnUJz00xK5fzxpg\"\n",
    "#     }\n",
    "\n",
    "#     response = requests.get(url, headers=headers)\n",
    "\n",
    "#     if response.status_code == 200 and 'title' in response.json():\n",
    "#         return response.json()['title']\n",
    "#     else:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_films['title_final_out_KNN'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_films['title_final_out_KNN'] = df_films['film_id_out_KNN'].apply(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_films[df_films['title_final_out_KNN'].isna() == True]['title_final_out_KNN'] = df_films[df_films['title_final_out_KNN'].isna() == True]['title_final_out_KNN'].fillna(df_films[df_films['title_final_out_KNN'].isna() == True]['title_out_KNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste_limitee_title = colonne_debut_titre(df_films, 'title_final_out_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_colonnes(df_films, liste_limitee_title, 'debut_critere_title_out_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = df_films.rename({'title_final_out_KNN' : 'title_final_out_KNN'}, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOOL DES COLONNES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = transfo_col_bool(df_films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes = list(df_films.select_dtypes(include = 'number').columns)\n",
    "supprimer = []\n",
    "\n",
    "df_null = pd.DataFrame(df_films[colonnes].sum()).transpose()\n",
    "\n",
    "for element in colonnes:\n",
    "    if df_null[element].iloc[0] == 0:\n",
    "        supprimer.append(element)\n",
    "\n",
    "if len(supprimer) > 0:\n",
    "    df_films = df_films.drop(supprimer, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILLNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films_str = df_films.select_dtypes(exclude = 'number')\n",
    "df_films_num = df_films.select_dtypes(include = 'number')\n",
    "df_films_str = df_films_str.fillna('Unknown')\n",
    "df_films_num = df_films_num.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = pd.concat([df_films_str, df_films_num], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films_str, df_films_num = 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'films' in df_films.columns:\n",
    "    df_films = df_films.drop(['films'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films.to_csv('P2_G5_films.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_films.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOIX DES CARACTERISTIQUES\n",
    "\n",
    "caracteristiques = []\n",
    "\n",
    "for element in df.columns:\n",
    "    if 'out_KNN' not in element:\n",
    "        caracteristiques.append(element)\n",
    "\n",
    "caracteristiques_num = []\n",
    "\n",
    "for element in df.select_dtypes(include = 'number').columns:\n",
    "    if 'out_KNN' not in element:\n",
    "        caracteristiques_num.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METTRE UNIQUEMENT POUR LES COLONNES NUMERIQUES\n",
    "\n",
    "poids_list = pd.DataFrame(columns = caracteristiques_num, index = ['poids'])\n",
    "\n",
    "colonne_cle = 10\n",
    "tres_important = 7\n",
    "important = 4\n",
    "bof = 1\n",
    "rien = 0\n",
    "\n",
    "poids = {\n",
    " 'popularity_final' : colonne_cle,\n",
    " 'year_final' : bof,\n",
    " 'Decennie' : tres_important,\n",
    " 'runtime_final' : rien,\n",
    " 'vote_exact_final' : important,\n",
    " 'vote_arrondi_final' : colonne_cle,\n",
    " 'vote_count_final' : tres_important,\n",
    " 'prod_US' : important,\n",
    " 'prod_FR' : important\n",
    "}\n",
    "\n",
    "for element in df.select_dtypes(include = 'number').columns:\n",
    "    if \"production_companies_name\" in element:\n",
    "        poids.update({element : important})\n",
    "    elif \"acteur_{\" in element:\n",
    "        poids.update({element : colonne_cle})\n",
    "    elif \"realisateurs_\" in element:\n",
    "        poids.update({element : colonne_cle})\n",
    "    elif \"genre_\" in element:\n",
    "        poids.update({element : colonne_cle})\n",
    "    # elif 'debut_critere_' in element:\n",
    "    #     poids.update({element : colonne_cle})\n",
    "    # else:\n",
    "    #      poids.update({element : rien})\n",
    "\n",
    "\n",
    "\n",
    "for element in poids_list.columns:\n",
    "    if element not in poids.keys():\n",
    "        poids.update({element : rien})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECHERCHE DU TITRE\n",
    "\n",
    "df_recherche = df.copy()\n",
    "df_recherche['title_final_out_KNN'] = df_recherche['title_final_out_KNN'].apply(lambda x : x.lower())\n",
    "recherche = 'hobbit smaug'\n",
    "recherche2 = recherche.lower().split(\" \")\n",
    "\n",
    "for element in recherche2:\n",
    "    df_recherche2 = df_recherche[df_recherche['title_final_out_KNN'].str.contains(element)]\n",
    "    df_recherche = df_recherche2\n",
    "\n",
    "display(df_recherche[['title_final_out_KNN','film_id_out_KNN', 'runtime_final', 'popularity_final', 'vote_exact_final']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_id = 'tt0120737'\n",
    "\n",
    "# BASES\n",
    "\n",
    "X = df[caracteristiques]\n",
    "\n",
    "df_a_predire = df[df['film_id_out_KNN'] == film_id]\n",
    "search = df_a_predire['title_final_out_KNN'].iloc[0]\n",
    "# df_a_predire = df_a_predire.drop('title_len_out_KNN', axis = 1)\n",
    "df_a_predire = df_a_predire[caracteristiques]\n",
    "\n",
    "\n",
    "k_range = (3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTION 1\n",
    "\n",
    "X_encoded, SN = encodage_X(X, 'standard', poids)\n",
    "\n",
    "# # FONCTION 2\n",
    "\n",
    "# avg_distances, silhouette_scores = evaluate_k(X_encoded, k_range)\n",
    "\n",
    "# # FONCTION 3\n",
    "\n",
    "df_final = encodage_predict(df_a_predire, SN, poids, X_encoded)\n",
    "\n",
    "# # FONCTION 4\n",
    "\n",
    "# On choisit k\n",
    "k=10\n",
    "\n",
    "model = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
    "model.fit(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caracteristiques.append('film_id_out_KNN')\n",
    "resultat = pokemons_similaires(df[caracteristiques], film_id, model, SN, poids, X_encoded, df)\n",
    "choix = pd.DataFrame(df[df['title_final_out_KNN'] == search])\n",
    "\n",
    "# # choix2 = choix.drop(columns = choix.columns[22:])\n",
    "# # resultat2 = resultat.drop(columns = resultat.columns[22:])\n",
    "\n",
    "final = pd.concat([choix, resultat])\n",
    "final = final.drop(0)\n",
    "\n",
    "caracteristiques.remove('film_id_out_KNN')\n",
    "\n",
    "final.transpose()\n",
    "final['title_final_out_KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORTER MODEL\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "with open('mon_modele.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
